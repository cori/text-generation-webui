codeup-alpha-13b-hf.ggmlv3.q5_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 19
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
codeup-llama-2-13b-chat-hf.ggmlv3.q5_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 19
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 5.0e-06
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
gpt4-alpaca-lora-30b.ggmlv3.q4_0.bin$:
  loader: llama.cpp
  cpu: false
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 7
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
wizardlm-33b-v1.0-uncensored.ggmlv3.q4_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
llama-30b-supercot.ggmlv3.q4_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 13
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
codellama-34b-instruct.ggmlv3.Q3_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 7
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
codellama-34b-instruct.ggmlv3.Q2_K.bin$:
  loader: llama.cpp
  cpu: false
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
codellama-34b-instruct.ggmlv3.Q4_0.bin$:
  loader: llama.cpp
  cpu: true
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 8
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
codellama-13b.ggmlv3.Q4_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 19
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
codellama-13b-instruct.ggmlv3.Q4_K_M.bin$:
  loader: llama.cpp
  cpu: false
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 21
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
samantha-1.11-codellama-34b.ggmlv3.Q2_K.bin$:
  loader: llama.cpp
  cpu: true
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 0
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
genz-70b.Q4_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 8
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 7
  tensor_split: ''
  n_ctx: 3072
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
samantha-1.11-codellama-34b.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
model_007-70b.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 7
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
phind-codellama-34b-v2.Q5_K_M.gguf:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 4096
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
yarn-llama-2-13b-64k.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 7
  tensor_split: ''
  n_ctx: 16384
  n_gqa: 0
  rms_norm_eps: 5.0e-06
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
codellama-34b-instruct.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 0
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
llama-2-coder-7b.Q6_K.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 13
  tensor_split: ''
  n_ctx: 2048
  n_gqa: 0
  rms_norm_eps: 5.0e-06
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
phind-codellama-34b-v2.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 2048
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
wizardcoder-python-13b-v1.0.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 4096
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
wizardcoder-python-34b-v1.0.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 9
  tensor_split: ''
  n_ctx: 2048
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
codellama-13b-instruct.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 11
  tensor_split: ''
  n_ctx: 4096
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
mammoth-coder-34b.Q5_K_M.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  mul_mat_q: false
  n_gpu_layers: 7
  tensor_split: ''
  n_ctx: 2048
  llama_cpp_seed: 0.0
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 1000000
